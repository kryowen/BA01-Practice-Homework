{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeVXiPZpVian"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "filepath = '/content/gdrive/MyDrive' + '/Colab Notebooks/csv/'\n",
        "mnist = np.load(filepath+'mnist.npz')\n",
        "\n",
        "x_train = (mnist['x_train'] - np.mean(mnist['x_train'])) / np.std(mnist['x_train'])\n",
        "y_train = mnist['y_train']\n",
        "x_test = (mnist['x_test'] - np.mean(mnist['x_train'])) / np.std(mnist['x_train'])\n",
        "y_test = mnist['y_test']\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x))\n",
        "    for i in range(len(x)):\n",
        "        exp_x[i] /= np.sum(exp_x[i])\n",
        "    return exp_x\n",
        "\n",
        "def hypothesis(w, x, b):\n",
        "    return softmax(x.dot(w) + b)\n",
        "\n",
        "def cross_entropy(y_true, y_pred): \n",
        "    y_true = np.argmax(y_true, axis=-1)\n",
        "    y_pred = y_pred[np.arange(y_true.shape[0]), y_true]\n",
        "    return -np.mean(np.log(y_pred + 1e-8))\n",
        "\n",
        "def to_onehot(labels, num_classes):\n",
        "    return np.eye(num_classes)[labels]"
      ],
      "metadata": {
        "id": "fxlmktUYx3Mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_onehot = to_onehot(y_train, 10)\n",
        "y_test_onehot = to_onehot(y_test, 10)\n",
        "\n",
        "print(y_train_onehot.shape, y_test_onehot.shape)"
      ],
      "metadata": {
        "id": "_0Pip9KtyFDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_small = x_train[:, ::4, ::4].reshape(-1, 7*7)\n",
        "x_test_small = x_test[:, ::4, ::4].reshape(-1, 7*7)\n",
        "\n",
        "print(x_train_small.shape, x_test_small.shape)"
      ],
      "metadata": {
        "id": "Armmu3_0yH2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = np.random.rand(7*7, 10)\n",
        "b = np.random.rand(10,)\n",
        "\n",
        "print(w.shape, b.shape)"
      ],
      "metadata": {
        "id": "jMzvk-8YyLee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 1000\n",
        "alpha = 1e-2\n",
        "sample_num = x_train_small.shape[0]\n",
        "\n",
        "total_loss = []\n",
        "for i in range(epoch):\n",
        "    h = hypothesis(w, x_train_small, b)\n",
        "    loss = cross_entropy(y_train_onehot, h)\n",
        "\n",
        "    for j in range(10):\n",
        "        grad = np.mean(x_train_small[:, j].dot((h - y_train_onehot[:][j])))\n",
        "        w[:, j] = w[:, j] - alpha * grad\n",
        "        b[j] = b[j] - alpha * np.mean(h - y_train_onehot[:][j])\n",
        "        \n",
        "    if i % 50 == 0:\n",
        "        print(f\"[Epoch : {i:3d}] Loss : {loss:.10f}\")\n",
        "    total_loss.append(loss)\n",
        "total_loss = np.array(total_loss) "
      ],
      "metadata": {
        "id": "bPC1grlsyN8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(10.0 * np.log(total_loss / (np.max(total_loss + 1e-5))))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eju5f3s1yYvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred_onehot = hypothesis(w, x_test_small, b)\n",
        "y_pred = np.argmax(y_pred_onehot, axis=-1)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "ZJ3l6jEQyadF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}